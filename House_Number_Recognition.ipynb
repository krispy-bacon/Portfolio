{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Project---Artificial-Neural-Networks:-Street-View-Housing-Number-Digit-Recognition\"><strong>Project - Artificial Neural Networks: Street View Housing Number Digit Recognition</strong><a class=\"anchor-link\" href=\"#Project---Artificial-Neural-Networks:-Street-View-Housing-Number-Digit-Recognition\">¶</a></h1><h1 \n",
    "id=\"Context:\"><strong>Context:</strong><a class=\"anchor-link\" href=\"#Context:\">¶</a></h3><hr/>\n",
    "<p>One of the most interesting tasks in deep learning is to recognize objects in natural scenes. The ability to process visual information using machine learning algorithms can be very useful as demonstrated in various applications.</p>\n",
    "<p>The SVHN dataset contains over 600,000 labeled digits cropped from street level photos. It is one of the most popular image recognition datasets. It has been used in neural networks created by Google to improve map quality by automatically transcribing the address numbers from a patch of pixels. The transcribed number with a known street address helps pinpoint the location of the building it represents.</p>\n",
    "<hr/>\n",
    "<h3 id=\"Objective:\"><strong>Objective:</strong><a class=\"anchor-link\" href=\"#Objective:\">¶</a></h3><hr/>\n",
    "<p>Build a feed forward neural network model that can identify the digits in the images.</p>\n",
    "<hr/>\n",
    "<h3 id=\"Dataset\"><strong>Dataset</strong><a class=\"anchor-link\" href=\"#Dataset\">¶</a></h3><hr/>\n",
    "<p>Here, we will use a subset of the original data to save some computation time. The dataset is provided as a .h5 file. The basic preprocessing steps have been done.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Mount-the-drive\"><strong>Mount the drive</strong><a class=\"anchor-link\" href=\"#Mount-the-drive\">¶</a></h2><p>Let us start by mounting the drive and importing the necessary libraries.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Importing-libraries\"><strong>Importing libraries</strong><a class=\"anchor-link\" href=\"#Importing-libraries\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let us check for the version of TensorFlow.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Load-the-dataset\"><strong>Load the dataset</strong><a class=\"anchor-link\" href=\"#Load-the-dataset\">¶</a></h2><ul>\n",
    "<li>Let us now load the dataset that is available as a .h5 file.</li>\n",
    "<li>Split the data into train and the test dataset</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the file as read only\n",
    "# User can make changes in the path as required\n",
    "h5f = h5py.File('/content/drive/MyDrive/SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training and the test set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "\n",
    "\n",
    "# Close this file\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's check the number of images in the training and testing data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations</strong></p>\n",
    "<ul>\n",
    "<li>There are 42,000 images in the training data and 18,000 images in the testing data. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Visualizing-images\"><strong>Visualizing images</strong><a class=\"anchor-link\" href=\"#Visualizing-images\">¶</a></h2><ul>\n",
    "<li>Use X_train to visualize the first 10 images</li>\n",
    "<li>Use Y_train to print the first 10 labels</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "plt.figure(figsize=(10, 1))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Data-preparation\"><strong>Data preparation</strong><a class=\"anchor-link\" href=\"#Data-preparation\">¶</a></h2><ul>\n",
    "<li>Print the first image in the train image and figure out the shape of the images</li>\n",
    "<li>Reshape the train and the test dataset to flatten them. Figure out the required shape</li>\n",
    "<li>Normalise the train and the test dataset by dividing by 255</li>\n",
    "<li>Print the new shapes of the train and the test set</li>\n",
    "<li>One-hot encode the target variable</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the images and the first image\n",
    "\n",
    "print(\"Shape:\", X_train[0].shape)\n",
    "print()\n",
    "print(\"First image:\\n\", X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the dataset to flatten them. Remember that we are trying to reshape the 2D image data into a 1D array\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1024)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Normalize-the-train-and-test-data\"><strong>Normalize the train and test data</strong><a class=\"anchor-link\" href=\"#Normalize-the-train-and-test-data-(2-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize inputs from 0-255 to 0-1\n",
    "\n",
    "X_train = MinMaxScaler().transform(X_train)\n",
    "x_test = MinMaxScaler().transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# New shape \n",
    "\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# one hot encode output\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# no.of classes\n",
    "y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations</strong></p>\n",
    "<ul>\n",
    "<li>Notice that each entry of y_test is a one-hot encoded vector instead of a single label.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Model-Building\"><strong>Model Building</strong><a class=\"anchor-link\" href=\"#Model-Building\">¶</a></h2><p>Now, we have done the data preprocessing, let's build an ANN model.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fixing the seed for random number generators\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Model-Architecture\"><strong>Model Architecture</strong><a class=\"anchor-link\" href=\"#Model-Architecture\">¶</a></h3><ul>\n",
    "<li>Write a function that returns a sequential model with the following architecture<ul>\n",
    "<li>First hidden layer with <strong>64 nodes and relu activation</strong> and the input shape which is used above</li>\n",
    "<li>Second hidden layer with <strong>32 nodes and relu activation</strong></li>\n",
    "<li>Output layer with <strong>softmax activation and number of nodes equal to the number of classes</strong>\n",
    "-Compile the model with the <strong>categorical_crossentropy loss, adam optimizer (learning_rate = 0.001), and accuracy metric</strong>. Do not fit the model here, just return the compiled model.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Call the function and store the model in a new variable </li>\n",
    "<li>Print the summary of the model</li>\n",
    "<li>Fit on the train data with a <strong>validation split of 0.2, batch size = 128, verbose = 1, and 20 epochs</strong>. Store the model building history to use later for visualization.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Question-2:-Build-and-train-a-ANN-model-as-per-the-above-mentioned-architecture-(10-Marks)\"><strong>Question 2: Build and train a ANN model as per the above mentioned architecture (10 Marks)</strong><a class=\"anchor-link\" href=\"#Question-2:-Build-and-train-a-ANN-model-as-per-the-above-mentioned-architecture-(10-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Importing losses and optimizers modules\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Define the function\n",
    "def nn_model_1():\n",
    "    model = Sequential() \n",
    "    #Add layers as per the architecture mentioned above in the same sequence\n",
    "    model.add(Dense(64, activation = 'relu', input_shape=(1024,)))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    #declare adam optimizer with learning rate of 0.001 \n",
    "    adam = optimizers.Adam(learning_rate = 0.001)\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "                  \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build the model\n",
    "model_1 = nn_model_1()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Print the summary\n",
    "model_1.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit the model\n",
    "history_model_1 = model_1.fit(X_train_normalized, \n",
    "                    y_train,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=128\n",
    "                    epochs=20, \n",
    "                    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Plotting-the-validation-and-training-accuracies\"><strong>Plotting the validation and training accuracies</strong><a class=\"anchor-link\" href=\"#Plotting-the-validation-and-training-accuracies\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Question-3:-Write-your-observations-on-the-below-plot-(2-Marks)\"><strong>Question 3: Write your observations on the below plot (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-3:-Write-your-observations-on-the-below-plot-(2-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotting the accuracies\n",
    "\n",
    "dict_hist = history_model_1.history\n",
    "list_ep = [i for i in range(1,21)]\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.plot(list_ep,dict_hist['accuracy'],ls = '--', label = 'accuracy')\n",
    "plt.plot(list_ep,dict_hist['val_accuracy'],ls = '--', label = 'val_accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:both are capping out around .65ish accuracy. There isn't much impovement after 12 Epochs</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's build one more model with higher complexity and see if we can improve the performance of the model.</p>\n",
    "<p>First, we need to clear the previous model's history from the keras backend. Also, let's fix the seed again after clearing the backend.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Clearing backend\n",
    "from tensorflow.keras import backend\n",
    "backend.clear_session()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fixing the seed for random number generators\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Second-Model-Architecture\"><strong>Second Model Architecture</strong><a class=\"anchor-link\" href=\"#Second-Model-Architecture\">¶</a></h3><ul>\n",
    "<li>Write a function that returns a sequential model with the following architecture<ul>\n",
    "<li>First hidden layer with <strong>256 nodes and relu activation</strong></li>\n",
    "<li>Second hidden layer with <strong>128 nodes and relu activation</strong></li>\n",
    "<li>Add the <strong>Dropout layer with rate equal to 0.2</strong></li>\n",
    "<li>Third hidden layer with <strong>64 nodes and relu activation</strong></li>\n",
    "<li>Fourth hidden layer with <strong>64 nodes and relu activation</strong></li>\n",
    "<li>Fifth hidden layer with <strong>32 nodes and relu activation</strong></li>\n",
    "<li>Add the <strong>BatchNormalization layer</strong></li>\n",
    "<li>Output layer with <strong>softmax activation and number of nodes equal to the number of classes</strong>\n",
    "-Compile the model with the <strong>categorical_crossentropy loss, adam optimizer (learning_rate = 0.0005), and accuracy metric</strong>. Do not fit the model here, just return the compiled model.</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>Call the function and store the model in a new variable </li>\n",
    "<li>Print the summary of the model</li>\n",
    "<li>Fit on the train data with a <strong>validation split of 0.2, batch size = 128, verbose = 1, and 30 epochs</strong>. Store the model building history to use later for visualization.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Question-4:-Build-and-train-the-new-ANN-model-as-per-the-above-mentioned-architecture-(10-Marks)\"><strong>Question 4: Build and train the new ANN model as per the above mentioned architecture (10 Marks)</strong><a class=\"anchor-link\" href=\"#Question-4:-Build-and-train-the-new-ANN-model-as-per-the-above-mentioned-architecture-(10-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Importing losses and optimizers modules\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#Define the function\n",
    "def nn_model_2():\n",
    "    model = Sequential() \n",
    "    #Add layers as per the architecture mentioned above in the same sequence\n",
    "    model.add(Dense(256, activation = 'relu', input_shape=(1024,)))\n",
    "    model.add(Dense(128, activation = 'relu', input_shape=(1024,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    #declare adam optimizer with learning rate of 0.0005 \n",
    "    adam = optimizers.Adam(learning_rate = 0.0005)\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Build the model\n",
    "model_2 = nn_model_2()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Print the model summary\n",
    "model_2.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit the model\n",
    "history_model_2 = model_2.fit(X_train_normalized, \n",
    "                    y_train,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=128\n",
    "                    epochs=30, \n",
    "                    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Plotting-the-validation-and-training-accuracies\"><strong>Plotting the validation and training accuracies</strong><a class=\"anchor-link\" href=\"#Plotting-the-validation-and-training-accuracies\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Question-5:-Write-your-observations-on-the-below-plot-(2-Marks)\"><strong>Question 5: Write your observations on the below plot (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-5:-Write-your-observations-on-the-below-plot-(2-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotting the accuracies\n",
    "\n",
    "dict_hist = history_model_2.history\n",
    "list_ep = [i for i in range(1,31)]\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.plot(list_ep,dict_hist['accuracy'],ls = '--', label = 'accuracy')\n",
    "plt.plot(list_ep,dict_hist['val_accuracy'],ls = '--', label = 'val_accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations:The validation accuracy matches the accuracy really well. This model has improved in accuracy overall as well, We are now capping out around 0.75</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Predictions-on-the-test-data\"><strong>Predictions on the test data</strong><a class=\"anchor-link\" href=\"#Predictions-on-the-test-data\">¶</a></h2><ul>\n",
    "<li>Make predictions on the test set using the second model</li>\n",
    "<li>Print the obtained results using the classification report and the confusion matrix</li>\n",
    "<li>Final observations from the obtained results</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_pred = model_2.predict(X_test)\n",
    "\n",
    "test_pred = np.argmax(test_pred, axis=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Note:</strong> Earlier, we noticed that each entry of the test data is a one-hot encoded vector but to print the classification report and confusion matrix, we must convert each entry of y_test to a single label.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Converting each entry to single label from one-hot encoded vector\n",
    "y_test = np.argmax(y_test, axis=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Question-6:-Print-the-classification-report-and-the-confusion-matrix-for-the-test-predictions.-Write-your-observations-on-the-final-results-(4-Marks)\"><strong>Question 6: Print the classification report and the confusion matrix for the test predictions. Write your observations on the final results (4 Marks)</strong><a class=\"anchor-link\" href=\"#Question-6:-Print-the-classification-report-and-the-confusion-matrix-for-the-test-predictions.-Write-your-observations-on-the-final-results-(4-Marks)\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#importing required functions\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Printing the classification report\n",
    "print(classification_report(y_test, test_pred))\n",
    "\n",
    "#Plotting the heatmap using confusion matrix\n",
    "cm = confusion_matrix(y_test, test_pred) #Write the code for creating confusion matrix using actual labels and predicted labels\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(cm, annot=True,  fmt='.0f')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

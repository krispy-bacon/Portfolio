{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Problem-Definition\"><b>Problem Definition</b><a class=\"anchor-link\" href=\"#Problem-Definition\">¶</a></h2><p><strong>The context:</strong> Why is this problem important to solve?<br/>\n",
    "    This problem is important to solve because it will improve the accuracy of determining who will mostly likely default on their loan. This will inturn help the bank give out better loads to people who will actually pay them back.<br/>\n",
    "<strong>The objectives:</strong> What is the intended goal?<br/>\n",
    "    The goal is to build a classification model that will take the given inputs and determine if the customer will default on their load or not. This model should be free of any bias. We will also give any recomendations back to the bank on any important features to consider when approving a loan. <br/>\n",
    "<strong>The key questions:</strong> What are the key questions that need to be answered?<br/>\n",
    "What are the key features to determine if someone will default on a loan? <br/>\n",
    "<strong>The problem formulation:</strong> What is it that we are trying to solve using data science?<br/>\n",
    "We are trying to use data science to eleminate the human error and bias that comes into determining if someone will default on the loan or not.</p>\n",
    "<h2 id=\"Data-Description:\"><strong>Data Description:</strong><a class=\"anchor-link\" href=\"#Data-Description:\">¶</a></h2><p>The Home Equity dataset (HMEQ) contains baseline and loan performance information for 5,960 recent home equity loans. The target (BAD) is a binary variable that indicates whether an applicant has ultimately defaulted or has been severely delinquent. This adverse outcome occurred in 1,189 cases (20 percent). 12 input variables were registered for each applicant.</p>\n",
    "<ul>\n",
    "<li><p><strong>BAD:</strong> 1 = Client defaulted on loan, 0 = loan repaid</p>\n",
    "</li>\n",
    "<li><p><strong>LOAN:</strong> Amount of loan approved.</p>\n",
    "</li>\n",
    "<li><p><strong>MORTDUE:</strong> Amount due on the existing mortgage.</p>\n",
    "</li>\n",
    "<li><p><strong>VALUE:</strong> Current value of the property.</p>\n",
    "</li>\n",
    "<li><p><strong>REASON:</strong> Reason for the loan request. (HomeImp = home improvement, DebtCon= debt consolidation which means taking out a new loan to pay off other liabilities and consumer debts)</p>\n",
    "</li>\n",
    "<li><p><strong>JOB:</strong> The type of job that loan applicant has such as manager, self, etc.</p>\n",
    "</li>\n",
    "<li><p><strong>YOJ:</strong> Years at present job.</p>\n",
    "</li>\n",
    "<li><p><strong>DEROG:</strong> Number of major derogatory reports (which indicates a serious delinquency or late payments).</p>\n",
    "</li>\n",
    "<li><p><strong>DELINQ:</strong> Number of delinquent credit lines (a line of credit becomes delinquent when a borrower does not make the minimum required payments 30 to 60 days past the day on which the payments were due).</p>\n",
    "</li>\n",
    "<li><p><strong>CLAGE:</strong> Age of the oldest credit line in months.</p>\n",
    "</li>\n",
    "<li><p><strong>NINQ:</strong> Number of recent credit inquiries.</p>\n",
    "</li>\n",
    "<li><p><strong>CLNO:</strong> Number of existing credit lines.</p>\n",
    "</li>\n",
    "<li><p><strong>DEBTINC:</strong> Debt-to-income ratio (all your monthly debt payments divided by your gross monthly income. This number is one way lenders measure your ability to manage the monthly payments to repay the money you plan to borrow.</p>\n",
    "</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Important-Notes\"><b>Important Notes</b><a class=\"anchor-link\" href=\"#Important-Notes\">¶</a></h2><ul>\n",
    "<li><p>This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise.</p>\n",
    "</li>\n",
    "<li><p>In the notebook, there are markdowns cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.</p>\n",
    "</li>\n",
    "<li><p>The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.</p>\n",
    "</li>\n",
    "<li><p>All the outputs in the notebook are just for reference and can be different if you follow a different approach.</p>\n",
    "</li>\n",
    "<li><p>There are sections called <strong>Think About It</strong> in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques.</p>\n",
    "</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Import-the-necessary-libraries\"><strong>Import the necessary libraries</strong><a class=\"anchor-link\" href=\"#Import-the-necessary-libraries\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,precision_score,recall_score,f1_score,precision_recall_curve\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Read-the-dataset\"><strong>Read the dataset</strong><a class=\"anchor-link\" href=\"#Read-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm=pd.read_csv(\"hmeq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying data to another variable to avoid any changes to original data\n",
    "data=hm.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Print-the-first-and-last-5-rows-of-the-dataset\"><strong>Print the first and last 5 rows of the dataset</strong><a class=\"anchor-link\" href=\"#Print-the-first-and-last-5-rows-of-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first five rows\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "# Remove ___________ and complete the code\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Understand-the-shape-of-the-dataset\"><strong>Understand the shape of the dataset</strong><a class=\"anchor-link\" href=\"#Understand-the-shape-of-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights There are some missing values, we can see this in the first five lines. We also have 12 imputs for our 1 output of BAD. There are 5960 rows of data in our data set. Having an option like \"other\" for job seems kind of vague. The missing values are going to need to be addressed if we want an accurate model.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Check-the-data-types-of-the-columns\"><strong>Check the data types of the columns</strong><a class=\"anchor-link\" href=\"#Check-the-data-types-of-the-columns\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check info of the data\n",
    "# Remove ___________ and complete the code\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: We have a lot of null values in multiple columns. Otherwise the data types all mades sense for thier respective columns.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Check-for-missing-values\"><strong>Check for missing values</strong><a class=\"anchor-link\" href=\"#Check-for-missing-values\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse missing values - Hint: use isnull() function\n",
    "# Remove ___________ and complete the code\n",
    "print(data.isnull())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values in the each column.\n",
    "# Hint: divide the result from the previous code by the number of rows in the dataset\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.isnull().sum() * 100 / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: We have several categories that are missing significant amount of data. Specifically DEBTINC, DEROG, and DELINQ.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>We found the total number of missing values and the percentage of missing values, which is better to consider?</li>\n",
    "<li>What can be the limit for % missing values in a column in order to avoid it and what are the challenges associated with filling them and avoiding them? </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>We can convert the object type columns to categories</strong></p>\n",
    "<p><code>converting \"objects\" to \"category\" reduces the data space required to store the dataframe</code></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Convert-the-data-types\"><strong>Convert the data types</strong><a class=\"anchor-link\" href=\"#Convert-the-data-types\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.select_dtypes(['object']).columns.tolist()\n",
    "\n",
    "#adding target variable to this list as this is an classification problem and the target variable is categorical\n",
    "\n",
    "cols.append('BAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of object type column to category. hint use astype() function\n",
    "# remove ___________ and complete the code\n",
    "\n",
    "for i in cols:\n",
    "    data[i] = data[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the info again and the datatype of different variable\n",
    "# remove ___________ and complete the code\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Analyze-Summary-Statistics-of-the-dataset\"><strong>Analyze Summary Statistics of the dataset</strong><a class=\"anchor-link\" href=\"#Analyze-Summary-Statistics-of-the-dataset\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the summary statistics for numerical variables\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights There seems to be some very high values of homes compared to the mean of 5,848, with the max beeing almost 200x bigger. DEROG seems to just have several outlayers on the high side with the majority of people having zero. The same can be said for DELINQ. The oldest credit line is almost 100 years old. That looks a little off. Also the max number of 71 credit lines is a little alarming as well. </strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summary for categorical data - Hint: inside describe function you can use the argument include=['category']\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "data.describe(include=['category']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights There seems to not be a lot of information with JOB since there are only 6 categories and the majority have chosen Other. This could be an area of improvment for the future. It also looks like the majority of our loans are not bad loans and are getting repaid which is a good thing, but can be improved. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Let's look at the unique values in all the categorical variables</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the count of unique values in each categorical column \n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "cols_cat= data.select_dtypes(['category'])\n",
    "\n",
    "for i in cols_cat.columns:\n",
    "    print('Unique values in',i, 'are :')\n",
    "    print(pd.unique(cols_cat[i]))\n",
    "    print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Both Reason and Job have NaN values which can be an issue. Also, the number of unique options for Job is very limited to just several positions. This could be an issue. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it\"><strong>Think about it</strong><a class=\"anchor-link\" href=\"#Think-about-it\">¶</a></h3><ul>\n",
    "<li>The results above gave the absolute count of unique values in each categorical column. Are absolute values a good measure? </li>\n",
    "<li>If not, what else can be used? Try implementing that. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Exploratory-Data-Analysis-(EDA)-and-Visualization\"><strong>Exploratory Data Analysis (EDA) and Visualization</strong><a class=\"anchor-link\" href=\"#Exploratory-Data-Analysis-(EDA)-and-Visualization\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Univariate-Analysis\"><strong>Univariate Analysis</strong><a class=\"anchor-link\" href=\"#Univariate-Analysis\">¶</a></h2><p>Univariate analysis is used to explore each variable in a data set, separately. It looks at the range of values, as well as the central tendency of the values. It can be done for both numerical and categorical variables</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"1.-Univariate-Analysis---Numerical-Data\"><strong>1. Univariate Analysis - Numerical Data</strong><a class=\"anchor-link\" href=\"#1.-Univariate-Analysis---Numerical-Data\">¶</a></h3><p>Histograms and box plots help to visualize and describe numerical data. We use box plot and histogram to analyze the numerical columns.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While doing uni-variate analysis of numerical variables we want to study their central tendency and dispersion.\n",
    "# Let us write a function that will help us create boxplot and histogram for any input numerical variable.\n",
    "# This function takes the numerical column as the input and return the boxplots and histograms for the variable.\n",
    "# Let us see if this help us write faster and cleaner code.\n",
    "def histogram_boxplot(feature, figsize=(15,10), bins = None):\n",
    "    \"\"\" Boxplot and histogram combined\n",
    "    feature: 1-d feature array\n",
    "    figsize: size of fig (default (9,8))\n",
    "    bins: number of bins (default None / auto)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(nrows = 2, # Number of rows of the subplot grid= 2\n",
    "                                           sharex = True, # x-axis will be shared among all subplots\n",
    "                                           gridspec_kw = {\"height_ratios\": (.25, .75)}, \n",
    "                                           figsize = figsize \n",
    "                                           ) # creating the 2 subplots\n",
    "    sns.boxplot(feature, ax=ax_box2, showmeans=True, color='violet') # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.distplot(feature, kde=F, ax=ax_hist2, bins=bins,palette=\"winter\") if bins else sns.distplot(feature, kde=False, ax=ax_hist2) # For histogram\n",
    "    ax_hist2.axvline(np.mean(feature), color='green', linestyle='--') # Add mean to the histogram\n",
    "    ax_hist2.axvline(np.median(feature), color='black', linestyle='-') # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Using-the-above-function,-let's-first-analyze-the-Histogram-and-Boxplot-for-LOAN\">Using the above function, let's first analyze the Histogram and Boxplot for LOAN<a class=\"anchor-link\" href=\"#Using-the-above-function,-let's-first-analyze-the-Histogram-and-Boxplot-for-LOAN\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the histogram boxplot for Loan\n",
    "histogram_boxplot(data['LOAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Our data is skewed to the right. It seems we have quite a few outlayers above the 4 quartile of our box plot. If that data is set aside, our data is pretty normally distributed. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Note:-As-done-above,-analyze-Histogram-and-Boxplot-for-other-variables\"><strong>Note:</strong> As done above, analyze Histogram and Boxplot for other variables<a class=\"anchor-link\" href=\"#Note:-As-done-above,-analyze-Histogram-and-Boxplot-for-other-variables\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the histogram boxplot for MORTDUE\n",
    "histogram_boxplot(data['MORTDUE'])\n",
    "\n",
    "# Build the histogram boxplot for VALUE\n",
    "histogram_boxplot(data['VALUE'])\n",
    "\n",
    "# Build the histogram boxplot for YOJ\n",
    "histogram_boxplot(data['YOJ'])\n",
    "\n",
    "# Build the histogram boxplot for DEROG\n",
    "histogram_boxplot(data['DEROG'])\n",
    "\n",
    "# Build the histogram boxplot for DELINQ\n",
    "histogram_boxplot(data['DELINQ'])\n",
    "\n",
    "# Build the histogram boxplot for CLAGE\n",
    "histogram_boxplot(data['CLAGE'])\n",
    "\n",
    "# Build the histogram boxplot for NINQ\n",
    "histogram_boxplot(data['NINQ'])\n",
    "\n",
    "# Build the histogram boxplot for CLNO\n",
    "histogram_boxplot(data['CLNO'])\n",
    "\n",
    "# Build the histogram boxplot for DEBTINC\n",
    "histogram_boxplot(data['DEBTINC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<pre><code>**Insights: MORTDUE is similar to LOAN in that it is skewed right with several outlayers in that direction. The majority of the data is normally distributed. For Value, we have some outlayers that are way out to the right, over 4x the mean. For YOJ we don't have a normal distribution. Most of the data is on the left with very few data points being over 10 years. For both DEROG and DELINQ, the majority of our data is 0, very few data points being over that. CLAGE is fairly noramally distrubited with a few outlays but they seem to be minimal. NINQ is pretty close to being 0 the majority of the time. CLNO is pretty normally distributed. NOt the smoothest and has several outlayers but still close to normal. DEBTINC looks a little left skewed. There are a few outlayers but doesn't look like too many. **</code></pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"2.-Univariate-Analysis---Categorical-Data\"><strong>2. Univariate Analysis - Categorical Data</strong><a class=\"anchor-link\" href=\"#2.-Univariate-Analysis---Categorical-Data\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create barplots that indicate percentage for each category.\n",
    "\n",
    "def perc_on_bar(plot, feature):\n",
    "    '''\n",
    "    plot\n",
    "    feature: categorical feature\n",
    "    the function won't work if a column is passed in hue parameter\n",
    "    '''\n",
    "\n",
    "    total = len(feature) # length of the column\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total) # percentage of each class of the category\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05 # width of the plot\n",
    "        y = p.get_y() + p.get_height()           # height of the plot\n",
    "        ax.annotate(percentage, (x, y), size = 12) # annotate the percentage \n",
    "        \n",
    "    plt.show() # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Analyze-Barplot-for-DELINQ\">Analyze Barplot for DELINQ<a class=\"anchor-link\" href=\"#Analyze-Barplot-for-DELINQ\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build barplot for DELINQ\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.countplot(data[\"DELINQ\"],palette='winter')\n",
    "perc_on_bar(ax,data[\"DELINQ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Over 85% of DELINQ take placy in 0-2, with everything being under 10.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Note:-As-done-above,-analyze-Histogram-and-Boxplot-for-other-variables.\"><strong>Note:</strong> As done above, analyze Histogram and Boxplot for other variables.<a class=\"anchor-link\" href=\"#Note:-As-done-above,-analyze-Histogram-and-Boxplot-for-other-variables.\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build barplot for DEROG\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.countplot(data[\"DEROG\"],palette='winter')\n",
    "perc_on_bar(ax,data[\"DEROG\"])\n",
    "\n",
    "#Build barplot for REASON\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.countplot(data[\"REASON\"],palette='winter')\n",
    "perc_on_bar(ax,data[\"REASON\"])\n",
    "\n",
    "#Build barplot for JOB\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.countplot(data[\"JOB\"],palette='winter')\n",
    "perc_on_bar(ax,data[\"JOB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Almost all of DEROG is less than 2. 2/3 of reasons for the loan have been Debt Consolidation. The vast majority of the jobs have been Other with ProfExe being the next hightest. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Bivariate-Analysis\"><strong>Bivariate Analysis</strong><a class=\"anchor-link\" href=\"#Bivariate-Analysis\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Bivariate-Analysis:-Continuous-and-Categorical-Variables\"><strong>Bivariate Analysis: Continuous and Categorical Variables</strong><a class=\"anchor-link\" href=\"#Bivariate-Analysis:-Continuous-and-Categorical-Variables\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Analyze-BAD-vs-Loan\">Analyze BAD vs Loan<a class=\"anchor-link\" href=\"#Analyze-BAD-vs-Loan\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data[\"BAD\"],data['LOAN'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: The loan value doesn't appear to have that much affect on whether its going to be a Good or BAD loan. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Note:-As-shown-above,-perform-Bi-Variate-Analysis-on-different-pair-of-Categorical-and-continuous-variables\"><strong>Note:</strong> As shown above, perform Bi-Variate Analysis on different pair of Categorical and continuous variables<a class=\"anchor-link\" href=\"#Note:-As-shown-above,-perform-Bi-Variate-Analysis-on-different-pair-of-Categorical-and-continuous-variables\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(data[\"BAD\"],data['MORTDUE'],palette=\"PuBu\")\n",
    "\n",
    "#sns.boxplot(data[\"BAD\"],data['VALUE'],palette=\"PuBu\")\n",
    "\n",
    "#sns.boxplot(data[\"BAD\"],data['YOJ'],palette=\"PuBu\")\n",
    "\n",
    "#sns.boxplot(data[\"BAD\"],data['CLAGE'],palette=\"PuBu\")\n",
    "\n",
    "#sns.boxplot(data[\"BAD\"],data['NINQ'],palette=\"PuBu\")\n",
    "\n",
    "#sns.boxplot(data[\"BAD\"],data['CLNO'],palette=\"PuBu\")\n",
    "\n",
    "sns.boxplot(data[\"BAD\"],data['DEBTINC'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Bivariate-Analysis:-Two-Continuous-Variables\"><strong>Bivariate Analysis: Two Continuous Variables</strong><a class=\"anchor-link\" href=\"#Bivariate-Analysis:-Two-Continuous-Variables\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data[\"VALUE\"],data['MORTDUE'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: There appears to be some correlation between MORTDUE and VALUE. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Note:-As-shown-above,-perform-Bivariate-Analysis-on-different-pairs-of-continuous-variables\"><strong>Note:</strong> As shown above, perform Bivariate Analysis on different pairs of continuous variables<a class=\"anchor-link\" href=\"#Note:-As-shown-above,-perform-Bivariate-Analysis-on-different-pairs-of-continuous-variables\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data[\"CLAGE\"],data['CLNO'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Majority of cred lines are not over 400 months old, so realativly less that 4 years old.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Bivariate-Analysis:--BAD-vs-Categorical-Variables\"><strong>Bivariate Analysis:  BAD vs Categorical Variables</strong><a class=\"anchor-link\" href=\"#Bivariate-Analysis:--BAD-vs-Categorical-Variables\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>The stacked bar chart (aka stacked bar graph)</strong> extends the standard bar chart from looking at numeric values across one categorical variable to two.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to plot stacked bar charts for categorical columns\n",
    "\n",
    "def stacked_plot(x):\n",
    "    sns.set(palette='nipy_spectral')\n",
    "    tab1 = pd.crosstab(x,data['BAD'],margins=True)\n",
    "    print(tab1)\n",
    "    print('-'*120)\n",
    "    tab = pd.crosstab(x,data['BAD'],normalize='index')\n",
    "    tab.plot(kind='bar',stacked=True,figsize=(10,5))\n",
    "    plt.legend(loc='lower left', frameon=False)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Plot-stacked-bar-plot-for-for-LOAN-and-REASON\">Plot stacked bar plot for for LOAN and REASON<a class=\"anchor-link\" href=\"#Plot-stacked-bar-plot-for-for-LOAN-and-REASON\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bar plot for BAD and REASON\n",
    "stacked_plot(data['REASON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: Around 20 percent of both DebtCon and HomeImp default on their loans. Slightly more on HomeImp.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Note:-As-shown-above,-perform-Bivariate-Analysis-on-different-pairs-of-Categorical-vs-BAD\"><strong>Note:</strong> As shown above, perform Bivariate Analysis on different pairs of Categorical vs BAD<a class=\"anchor-link\" href=\"#Note:-As-shown-above,-perform-Bivariate-Analysis-on-different-pairs-of-Categorical-vs-BAD\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bar plot for BAD and REASON\n",
    "stacked_plot(data['JOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bar plot for BAD and REASON\n",
    "stacked_plot(data['DEROG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked bar plot for BAD and REASON\n",
    "stacked_plot(data['DELINQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: sALES and Self Employeed have the highest numbers of defaults. As DEROG increas, Defaluts increase significantly. Same as DELINQ. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Multivariate-Analysis\"><strong>Multivariate Analysis</strong><a class=\"anchor-link\" href=\"#Multivariate-Analysis\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Analyze-Correlation-Heatmap-for-Numerical-Variables\">Analyze Correlation Heatmap for Numerical Variables<a class=\"anchor-link\" href=\"#Analyze-Correlation-Heatmap-for-Numerical-Variables\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating numerical variables\n",
    "numerical_col = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Build correlation matrix for numerical columns\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "corr = data[numerical_col].corr()\n",
    "\n",
    "# plot the heatmap\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(corr,cmap='coolwarm',vmax=1,vmin=-1,\n",
    "        fmt=\".2f\",\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pairplot for the data with hue = 'BAD'\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "sns.pairplot(data=data, hue = 'BAD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it\"><strong>Think about it</strong><a class=\"anchor-link\" href=\"#Think-about-it\">¶</a></h3><ul>\n",
    "<li>Are there missing values and outliers in the dataset? If yes, how can you treat them? </li>\n",
    "<li>Can you think of different ways in which this can be done and when to treat these outliers or not?</li>\n",
    "<li>Can we create new features based on Missing values?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Treating-Outliers\">Treating Outliers<a class=\"anchor-link\" href=\"#Treating-Outliers\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_outliers(df,col):\n",
    "    '''\n",
    "    treats outliers in a varaible\n",
    "    col: str, name of the numerical varaible\n",
    "    df: data frame\n",
    "    col: name of the column\n",
    "    '''\n",
    "    \n",
    "    Q1=df.quantile(q=0.25, axis=1) # 25th quantile\n",
    "    Q3=df.quantile(q=0.75, axis=1)  # 75th quantile\n",
    "    IQR=Q3-Q1   # IQR Range\n",
    "    Lower_Whisker = Q1-(1.5*IQR) #define lower whisker\n",
    "    Upper_Whisker = Q3+(1.5*IQR)  # define upper Whisker\n",
    "    df[col] = np.clip(df[col], Lower_Whisker, Upper_Whisker) # all the values samller than Lower_Whisker will be assigned value of Lower_whisker \n",
    "                                                            # and all the values above upper_whishker will be assigned value of upper_Whisker \n",
    "    return df\n",
    "\n",
    "def treat_outliers_all(df, col_list):\n",
    "    '''\n",
    "    treat outlier in all numerical varaibles\n",
    "    col_list: list of numerical varaibles\n",
    "    df: data frame\n",
    "    '''\n",
    "    for c in col_list:\n",
    "        df = treat_outliers(df,c)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = data.copy()\n",
    "\n",
    "numerical_col = df_raw.select_dtypes(include=np.number).columns.tolist()# getting list of numerical columns\n",
    "\n",
    "df = treat_outliers_all(df_raw, numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"BAD\"],df['DEBTINC'],palette=\"PuBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Adding-new-columns-in-the-dataset-for-each-column-which-has-missing-values\">Adding new columns in the dataset for each column which has missing values<a class=\"anchor-link\" href=\"#Adding-new-columns-in-the-dataset-for-each-column-which-has-missing-values\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each column we create a binary flag for the row, if there is missing value in the row, then 1 else 0. \n",
    "def add_binary_flag(df,col):\n",
    "    '''\n",
    "    df: It is the dataframe\n",
    "    col: it is column which has missing values\n",
    "    It returns a dataframe which has binary falg for missing values in column col\n",
    "    '''\n",
    "    new_col = str(col)\n",
    "    new_col += '_missing_values_flag'\n",
    "    df[new_col] = df[col].isna()\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# list of columns that has missing values in it\n",
    "missing_col = [col for col in df.columns if df[col].isnull().any()]\n",
    "\n",
    "for colmn in missing_col:\n",
    "    add_binary_flag(df,colmn)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Filling-missing-values-in-numerical-columns-with-median-and-mode-in-categorical-variables\">Filling missing values in numerical columns with median and mode in categorical variables<a class=\"anchor-link\" href=\"#Filling-missing-values-in-numerical-columns-with-median-and-mode-in-categorical-variables\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Treat Missing values in numerical columns with median and mode in categorical variables\n",
    "# Select numeric columns.\n",
    "num_data = df.select_dtypes('number')\n",
    "\n",
    "# Select string and object columns.\n",
    "cat_data = df.select_dtypes('category').columns.tolist()#df.select_dtypes('object')\n",
    "\n",
    "# Fill numeric columns with median.\n",
    "# Remove _________ and complete the code\n",
    "df[num_data.columns] = num_data.fillna(df.median())\n",
    "\n",
    "# Fill object columns with model.\n",
    "# Remove _________ and complete the code\n",
    "for column in cat_data:\n",
    "    mode = df[column].mode()[0]\n",
    "    df[column] = df[column].fillna(mode)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.boxplot(df[\"BAD\"],df['CLAGE'],palette=\"PuBu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.pairplot(data=df, hue = 'BAD')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Proposed-approach\"><strong>Proposed approach</strong><a class=\"anchor-link\" href=\"#Proposed-approach\">¶</a></h2><p><strong>1. Potential techniques</strong> - What different techniques should be explored?\n",
    "        We should look at different ML tecniques like Random Forests and decision trees.</p>\n",
    "<p><strong>2. Overall solution design</strong> - What is the potential solution design?</p>\n",
    "<p><strong>3. Measures of success</strong> - What are the key measures of success?\n",
    "        The keys for success are going to be limiting the number of loans that default, that get classified as good.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Model-Building---Approach\"><strong>Model Building - Approach</strong><a class=\"anchor-link\" href=\"#Model-Building---Approach\">¶</a></h2><ol>\n",
    "<li>Data preparation</li>\n",
    "<li>Partition the data into train and test set</li>\n",
    "<li>Fit on the train data</li>\n",
    "<li>Tune the model and prune the tree, if required</li>\n",
    "<li>Test the model on test set</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Data-Preparation\"><strong>Data Preparation</strong><a class=\"anchor-link\" href=\"#Data-Preparation\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Separating-the-target-variable-from-other-variables\"><strong>Separating the target variable from other variables</strong><a class=\"anchor-link\" href=\"#Separating-the-target-variable-from-other-variables\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop the dependent variable from the dataframe and create the X(independent variable) matrix\n",
    "# Remove _________ and complete the code\n",
    "X = df.drop(['BAD'], axis=1)\n",
    "\n",
    "# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n",
    "# Remove _________ and complete the code\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create y(dependent varibale)\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y = df.BAD\n",
    "X.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Splitting-the-data-into-70%-train-and-30%-test-set\"><strong>Splitting the data into 70% train and 30% test set</strong><a class=\"anchor-link\" href=\"#Splitting-the-data-into-70%-train-and-30%-test-set\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it\"><strong>Think about it</strong><a class=\"anchor-link\" href=\"#Think-about-it\">¶</a></h3><ul>\n",
    "<li>You can try different splits like 70:30 or 80:20 as per your choice. Does this change in split affect the performance?</li>\n",
    "<li>If the data is imbalanced, can you make the split more balanced and if yes, how?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_2,x_test_2,y_train_2,y_test_2=train_test_split(X,y,test_size=0.2,random_state=1,stratify=y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Model-Evaluation-Criterion\"><strong>Model Evaluation Criterion</strong><a class=\"anchor-link\" href=\"#Model-Evaluation-Criterion\">¶</a></h2><h4 id=\"After-understanding-the-problem-statement,-think-about-which-evaluation-metrics-to-consider-and-why.\">After understanding the problem statement, think about which evaluation metrics to consider and why.<a class=\"anchor-link\" href=\"#After-understanding-the-problem-statement,-think-about-which-evaluation-metrics-to-consider-and-why.\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#creating metric function \n",
    "def metrics_score(actual, predicted):\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm, annot=True,  fmt='.2f', xticklabels=['Not Eligible', 'Eligible'], yticklabels=['Not Eligible', 'Eligible'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Build-a-Logistic-Regression-Model\"><strong>Build a Logistic Regression Model</strong><a class=\"anchor-link\" href=\"#Build-a-Logistic-Regression-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Defining the Logistic regression model\n",
    "# Remove _________ and complete the code\n",
    "log_reg= LogisticRegression()\n",
    "log_reg_2= LogisticRegression()\n",
    "\n",
    "# Fitting the model on the training data \n",
    "# Remove _________ and complete the code\n",
    "\n",
    "log_reg.fit(x_train,y_train)\n",
    "log_reg_2.fit(x_train_2,y_train_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Predict for train set\n",
    "# Remove _________ and complete the code\n",
    "y_pred_train = log_reg.predict(x_train)\n",
    "\n",
    "#checking the performance on the train dataset\n",
    "# Remove _________ and complete the code\n",
    "metrics_score(y_train, y_pred_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Predict for train set\n",
    "# Remove _________ and complete the code\n",
    "y_pred_train_2 = log_reg_2.predict(x_train_2)\n",
    "\n",
    "#checking the performance on the train dataset\n",
    "# Remove _________ and complete the code\n",
    "metrics_score(y_train_2, y_pred_train_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Predict for test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_test = log_reg.predict(x_test)\n",
    "\n",
    "#checking the performance on the test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "metrics_score(y_test, y_pred_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations: The model is doing a really good job on corretly predictly Not Eligible as well as limiting those predicted Eligible that are Not Eligible. The model does a terrible job at predictly Eligible, this is not quite as important as we are looking for predicting defaults. </strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Predict for test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_test_2 = log_reg.predict(x_test_2)\n",
    "\n",
    "#checking the performance on the test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "metrics_score(y_test_2, y_pred_test_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Let's-check-the-coefficients,-and-check-which-variables-are-important-and-how-they-affect-the-process-of-loan-approval\">Let's check the coefficients, and check which variables are important and how they affect the process of loan approval<a class=\"anchor-link\" href=\"#Let's-check-the-coefficients,-and-check-which-variables-are-important-and-how-they-affect-the-process-of-loan-approval\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Printing the coefficients of logistic regression\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "pd.Series(log_reg.coef_[0], index=x_train.columns).sort_values(ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights DELINQ has the largest affect on our model, followed by DEROG. These both make sense since deliquencies seem to be a good indicator if someone will payback their loan. It look like the missing values of DEBTINC could play a role in this as well. Maybe if the bank were to obtain that information we could build a better model. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>The above Logistic regression model was build on the threshold of 0.5, can we use different threshold?</li>\n",
    "<li>How to get an optimal threshold and which curve will help you achieve? - Precision-Recall Curve for Logistic Regression</li>\n",
    "<li>How does, accuracy, precision and recall change on the threshold?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_scores=log_reg.predict_proba(x_train) #predict_proba gives the probability of each observation belonging to each class\n",
    "\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train, y_scores[:,1])\n",
    "\n",
    "#Plot values of precisions, recalls, and thresholds\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(thresholds, precisions[:-1], 'b--', label='precision')\n",
    "plt.plot(thresholds, recalls[:-1], 'g--', label = 'recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([0,1])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#calculating the exact threshold where precision and recall are equal.\n",
    "for i in np.arange(len(thresholds)):\n",
    "    if precisions[i]==recalls[i]:\n",
    "        print(thresholds[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimal_threshold1 = 0.326\n",
    "metrics_score(y_train, y_scores[:,1]>optimal_threshold1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Build-a-Decision-Tree-Model\"><strong>Build a Decision Tree Model</strong><a class=\"anchor-link\" href=\"#Build-a-Decision-Tree-Model\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>In Logistic regression we treated the outliers and built the model, should we do the same for tree based models or not? If not, why?</li>\n",
    "</ul>\n",
    "<p>We do not need to remove outliers since the decision tree will naturally eliminate irrelevant features.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Data-Preparation-for-the-tree-based-model\">Data Preparation for the tree based model<a class=\"anchor-link\" href=\"#Data-Preparation-for-the-tree-based-model\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add binary flags\n",
    "# List of columns that has missing values in it\n",
    "missing_col = [col for col in data.columns if data[col].isnull().any()]\n",
    "\n",
    "for colmn in missing_col:\n",
    "    add_binary_flag(data,colmn)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Treat Missing values in numerical columns with median and mode in categorical variables\n",
    "# Select numeric columns.\n",
    "num_data = data.select_dtypes('number')\n",
    "\n",
    "# Select string and object columns.\n",
    "cat_data = data.select_dtypes('category').columns.tolist()#df.select_dtypes('object')\n",
    "\n",
    "# Fill numeric columns with median.\n",
    "# Remove _________ and complete the code\n",
    "data[num_data.columns] = num_data.fillna(data.median())\n",
    "\n",
    "# Fill object columns with model.\n",
    "# Remove _________ and complete the code\n",
    "for column in cat_data:\n",
    "    mode = data[column].mode()[0]\n",
    "    data[column] = data[column].fillna(mode)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Separating-the-target-variable-y-and-independent-variable-x\">Separating the target variable y and independent variable x<a class=\"anchor-link\" href=\"#Separating-the-target-variable-y-and-independent-variable-x\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop dependent variable from dataframe and create the X(independent variable) matrix\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "X = data.drop(['BAD'], axis=1)\n",
    "\n",
    "# Create dummy variables for the categorical variables - Hint: use the get_dummies() function\n",
    "# Remove _________ and complete the code\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Create y(dependent varibale)\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y = data.BAD\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Split-the-data\">Split the data<a class=\"anchor-link\" href=\"#Split-the-data\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and test set\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1,stratify=y) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Defining Decision tree model with class weights class_weight={0: 0.2, 1: 0.8}\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight={0:0.2,1:0.8}, random_state=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#fitting Decision tree model\n",
    "# Remove ___________ and complete the code\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the training data\n",
    "# Remove ___________ and complete the code\n",
    "\n",
    "y_train_pred_dt=dt.predict(x_train)\n",
    "metrics_score(y_train,y_train_pred_dt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the testing data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_test_pred_dt=dt.predict(x_test)\n",
    "metrics_score(y_test,y_test_pred_dt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights This ran perfectly on the train data and not so well on the test. This leads me to believe the this model is overfitting. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>Can we improve this model? <ul>\n",
    "<li>Yes - the moddel is over fitting and need to be adjust </li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>How to get optimal parameters in order to get the best possible results?<ul>\n",
    "<li>We can plot feature importance to see which features are having the greates effect</li>\n",
    "<li>We can use grid search to hyper tun the parameters</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Decision-Tree---Hyperparameter-Tuning\"><strong>Decision Tree - Hyperparameter Tuning</strong><a class=\"anchor-link\" href=\"#Decision-Tree---Hyperparameter-Tuning\">¶</a></h3><ul>\n",
    "<li>Hyperparameter tuning is tricky in the sense that <strong>there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model</strong>, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.</li>\n",
    "<li><strong>Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.</strong> </li>\n",
    "<li><strong>It is an exhaustive search</strong> that is performed on the specific parameter values of a model.</li>\n",
    "<li>The parameters of the estimator/model used to apply these methods are <strong>optimized by cross-validated grid-search</strong> over a parameter grid.</li>\n",
    "</ul>\n",
    "<p><strong>Criterion {“gini”, “entropy”}</strong></p>\n",
    "<p>The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.</p>\n",
    "<p><strong>max_depth</strong></p>\n",
    "<p>The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.</p>\n",
    "<p><strong>min_samples_leaf</strong></p>\n",
    "<p>The minimum number of samples is required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.</p>\n",
    "<p>You can learn about more Hyperpapameters on this link and try to tune them.</p>\n",
    "<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Using-GridSearchCV-for-Hyperparameter-tuning-on-the-model\">Using GridSearchCV for Hyperparameter tuning on the model<a class=\"anchor-link\" href=\"#Using-GridSearchCV-for-Hyperparameter-tuning-on-the-model\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Choose the type of classifier. \n",
    "# Remove _________ and complete the code\n",
    "dtree_estimator = DecisionTreeClassifier(class_weight={0:0.2,1:0.8}, random_state=1)\n",
    "\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "# Remove _________ and complete the code\n",
    "parameters = {'max_depth': np.arange(2,7), \n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_leaf': [5, 10, 20, 25]\n",
    "             }\n",
    "\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "# Remove _________ and complete the code\n",
    "scorer = metrics.make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "# Remove _________ and complete the code\n",
    "gridCV= GridSearchCV(dtree_estimator, parameters, scoring=scorer,cv=10)\n",
    "\n",
    "\n",
    "# Fit the GridSearch on train dataset\n",
    "# Remove _________ and complete the code\n",
    "gridCV = gridCV.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "# Remove _________ and complete the code\n",
    "dtree_estimator = gridCV.best_estimator_\n",
    "\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# Remove _________ and complete the code\n",
    "dtree_estimator.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the training data based on the tuned model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_train_pred_dt=dtree_estimator.predict(x_train)\n",
    "metrics_score(y_train,y_train_pred_dt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the testing data based on the tuned model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_test_pred_dt=dtree_estimator.predict(x_test)\n",
    "metrics_score(y_test,y_test_pred_dt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights This model is much improved from the previous. Its not over fitting as the train and the test both have a recall of 0.89 and the f1-score and precision are right around the same values as well. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Plotting-the-Decision-Tree\">Plotting the Decision Tree<a class=\"anchor-link\" href=\"#Plotting-the-Decision-Tree\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot the decision  tree and analyze it to build the decision rule\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "features = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "\n",
    "tree.plot_tree(dt,max_depth=5,feature_names=features,filled=True,fontsize=12,node_ids=True,class_names=True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Deduce-the-business-rules-apparent-from-the-Decision-Tree-and-write-them-down:-Debt-to-income-less-than-43.7,-Deliquencies-less-than-1,-and-Credit-Line-ages-less-than-182-month-and-you-will-not-default-on-your-loan.\">Deduce the business rules apparent from the Decision Tree and write them down: Debt to income less than 43.7, Deliquencies less than 1, and Credit Line ages less than 182 month and you will not default on your loan.<a class=\"anchor-link\" href=\"#Deduce-the-business-rules-apparent-from-the-Decision-Tree-and-write-them-down:-Debt-to-income-less-than-43.7,-Deliquencies-less-than-1,-and-Credit-Line-ages-less-than-182-month-and-you-will-not-default-on-your-loan.\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Building-a-Random-Forest-Classifier\"><strong>Building a Random Forest Classifier</strong><a class=\"anchor-link\" href=\"#Building-a-Random-Forest-Classifier\">¶</a></h3><p><strong>Random Forest is a bagging algorithm where the base models are Decision Trees.</strong> Samples are taken from the training data and on each sample a decision tree makes a prediction.</p>\n",
    "<p><strong>The results from all the decision trees are combined together and the final prediction is made using voting or averaging.</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Defining Random forest CLassifier\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "rf_estimator = RandomForestClassifier()\n",
    "rf_estimator.fit(x_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Checking performance on the training data\n",
    "# Remove _________ and complete the code\n",
    "y_pred_train_rf = rf_estimator.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the test data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_test_rf = rf_estimator.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Observations: The model seems to be overfitting on the training set of data, however its still performing very well on the test data. There could still be room for improvment. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Build-a-Random-Forest-model-with-Class-Weights\"><strong>Build a Random Forest model with Class Weights</strong><a class=\"anchor-link\" href=\"#Build-a-Random-Forest-model-with-Class-Weights\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Defining Random Forest model with class weights class_weight={0: 0.2, 1: 0.8}\n",
    "\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight={0:0.2,1:0.8})\n",
    "\n",
    "# Fitting Random Forest model\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "rf_model.fit(x_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the train data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_train_rf = rf_model.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Checking performance on the test data\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_test_rf = rf_model.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>Can we try different weights?</li>\n",
    "<li>If yes, should we increase or decrease class weights for different classes? </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Tuning-the-Random-Forest\"><strong>Tuning the Random Forest</strong><a class=\"anchor-link\" href=\"#Tuning-the-Random-Forest\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li>Hyperparameter tuning is tricky in the sense that <strong>there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model</strong>, so we usually resort to experimentation. We'll use Grid search to perform hyperparameter tuning.</li>\n",
    "<li><strong>Grid search is a tuning technique that attempts to compute the optimum values of hyperparameters.</strong> </li>\n",
    "<li><strong>It is an exhaustive search</strong> that is performed on the specific parameter values of a model.</li>\n",
    "<li>The parameters of the estimator/model used to apply these methods are <strong>optimized by cross-validated grid-search</strong> over a parameter grid.</li>\n",
    "</ul>\n",
    "<p><strong>n_estimators</strong>: The number of trees in the forest.</p>\n",
    "<p><strong>min_samples_split</strong>: The minimum number of samples required to split an internal node:</p>\n",
    "<p><strong>min_samples_leaf</strong>: The minimum number of samples required to be at a leaf node.</p>\n",
    "<p><strong>max_features{“auto”, “sqrt”, “log2”, 'None'}</strong>: The number of features to consider when looking for the best split.</p>\n",
    "<ul>\n",
    "<li><p>If “auto”, then max_features=sqrt(n_features).</p>\n",
    "</li>\n",
    "<li><p>If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).</p>\n",
    "</li>\n",
    "<li><p>If “log2”, then max_features=log2(n_features).</p>\n",
    "</li>\n",
    "<li><p>If None, then max_features=n_features.</p>\n",
    "</li>\n",
    "</ul>\n",
    "<p>You can learn more about Random Forest Hyperparameters from the link given below and try to tune them</p>\n",
    "<p><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Warning:-This-may-take-a-long-time-depending-on-the-parameters-you-tune.\"><strong>Warning:</strong> This may take a long time depending on the parameters you tune.<a class=\"anchor-link\" href=\"#Warning:-This-may-take-a-long-time-depending-on-the-parameters-you-tune.\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "# Remove _________ and complete the code\n",
    "rf_estimator_tuned = RandomForestClassifier(class_weight={0:0.2,1:0.8})\n",
    "\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "# Remove _________ and complete the code\n",
    "params_rf = {  \n",
    "        \"n_estimators\": [100,250,500],\n",
    "        \"min_samples_leaf\": np.arange(1, 4,1),\n",
    "        \"max_features\": [0.7,0.9,'auto'],\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "# Remove _________ and complete the code\n",
    "scorer = metrics.make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "\n",
    "# Run the grid search\n",
    "# Remove _________ and complete the code\n",
    "grid_obj = GridSearchCV(rf_estimator_tuned, params_rf, scoring=scorer, cv=5)\n",
    "\n",
    "\n",
    "#fit the GridSearch on train dataset\n",
    "# Remove _________ and complete the code\n",
    "grid_obj = grid_obj.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "# Remove _________ and complete the code\n",
    "rf_estimator_tuned = grid_obj.best_estimator_\n",
    "\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# Remove _________ and complete the code\n",
    "rf_estimator_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-train-dataset\">Checking the performance on the train dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-train-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "# Remove _________ and complete the code\n",
    "y_pred_train_rf_tuned = rf_estimator_tuned.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_rf_tuned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Checking-the-performance-on-the-test-dataset\">Checking the performance on the test dataset<a class=\"anchor-link\" href=\"#Checking-the-performance-on-the-test-dataset\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performace on test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "y_pred_test_rf_tuned = rf_estimator_tuned.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_rf_tuned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: There is some slight improvement in precision. It doesn't appear to be over fitting on this one. Maybe we could tweek the parameters for futher improvment. </strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4 id=\"Plot-the-Feature-importance-of-the-tuned-Random-Forest\">Plot the Feature importance of the tuned Random Forest<a class=\"anchor-link\" href=\"#Plot-the-Feature-importance-of-the-tuned-Random-Forest\">¶</a></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of features in the tree building ( The importance of a feature is computed as the \n",
    "#(normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance )\n",
    "# Checking performace on test dataset\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "importances = rf_estimator_tuned.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Think-about-it:\"><strong>Think about it:</strong><a class=\"anchor-link\" href=\"#Think-about-it:\">¶</a></h3><ul>\n",
    "<li>We have only built 3 models so far, Logistic Regression, Decision Tree and Random Forest </li>\n",
    "<li>We can build other Machine Learning classification models like kNN, LDA, QDA or even Support Vector Machines (SVM).</li>\n",
    "<li>Can we also perform feature engineering and create model features and build a more robust and accurate model for this problem statement? </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# We select the best value of k for which the error rate is the least in the validation data\n",
    "# Let us loop over a few values of k to determine the best k\n",
    "\n",
    "train_error = []\n",
    "test_error = []\n",
    "knn_many_split = {}\n",
    "\n",
    "error_df_knn = pd.DataFrame()\n",
    "features = X.columns\n",
    "\n",
    "for k in range(1,15):\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    lista = []\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    for i in range(30):\n",
    "        x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size = 0.20)\n",
    "    \n",
    "        #Fitting knn on training data\n",
    "        knn.fit(x_train_new, y_train_new)\n",
    "        #Calculating error on training and validation data\n",
    "        train_error.append(1 - knn.score(x_train_new, y_train_new)) \n",
    "        test_error.append(1 - knn.score(x_val, y_val))\n",
    "    lista.append(sum(train_error)/len(train_error))\n",
    "    lista.append(sum(test_error)/len(test_error))\n",
    "    knn_many_split[k] = lista\n",
    "\n",
    "knn_many_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "kltest = []\n",
    "vltest = []\n",
    "for k, v in knn_many_split.items():\n",
    "    kltest.append(k)\n",
    "    vltest.append(knn_many_split[k][1])\n",
    "\n",
    "kltrain = []\n",
    "vltrain = []\n",
    "\n",
    "for k, v in knn_many_split.items():\n",
    "    kltrain.append(k)\n",
    "    vltrain.append(knn_many_split[k][0])\n",
    "\n",
    "# Plotting k vs error\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(kltest,vltest, label = 'test' )\n",
    "plt.plot(kltrain,vltrain, label = 'train')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#define knn model\n",
    "knn=KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#fitting data to the KNN model\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#checking the performance of knn model\n",
    "y_pred_train_knn = knn.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_knn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_test_knn = knn.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_knn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params_knn={'n_neighbors':np.arange(3,15),'weights':['uniform','distance'],'p':[1,2]}\n",
    "\n",
    "grid_knn=GridSearchCV(estimator=knn,param_grid=params_knn,scoring='recall',cv=10)\n",
    "\n",
    "model_knn=grid_knn.fit(x_train,y_train)\n",
    "\n",
    "knn_estimator = model_knn.best_estimator_\n",
    "print(knn_estimator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Fit the best estimator on the training data\n",
    "knn_estimator.fit(x_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_train_knn_estimator = knn_estimator.predict(x_train)\n",
    "metrics_score(y_train, y_pred_train_knn_estimator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_test_knn_estimator = knn_estimator.predict(x_test)\n",
    "metrics_score(y_test, y_pred_test_knn_estimator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Comparing-Model-Performances\"><strong>Comparing Model Performances</strong><a class=\"anchor-link\" href=\"#Comparing-Model-Performances\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_recall_score(model,flag=True,x_train=x_train,x_test=x_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    a = [] # defining an empty list to store train and test results\n",
    "    pred_train = model.predict(x_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    train_recall = metrics.recall_score(y_train,pred_train)\n",
    "    test_recall = metrics.recall_score(y_test,pred_test)\n",
    "    a.append(train_recall) # adding train recall to list \n",
    "    a.append(test_recall) # adding test recall to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n",
    "        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n",
    "    \n",
    "    return a # returning the list with train and test scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##  Function to calculate precision score\n",
    "def get_precision_score(model,flag=True,x_train=x_train,x_test=x_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    b = []  # defining an empty list to store train and test results\n",
    "    pred_train = model.predict(x_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    train_precision = metrics.precision_score(y_train,pred_train)\n",
    "    test_precision = metrics.precision_score(y_test,pred_test)\n",
    "    b.append(train_precision) # adding train precision to list\n",
    "    b.append(test_precision) # adding test precision to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n",
    "        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n",
    "\n",
    "    return b # returning the list with train and test scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##  Function to calculate accuracy score\n",
    "def get_accuracy_score(model,flag=True,X_train=x_train,X_test=x_test):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    c = [] # defining an empty list to store train and test results\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    c.append(train_acc) # adding train accuracy to list\n",
    "    c.append(test_acc) # adding test accuracy to list\n",
    "    \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True:\n",
    "        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n",
    "        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n",
    "    \n",
    "    return c # returning the list with train and test scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make the list of all the model names \n",
    "\n",
    "models = [log_reg, dtree_estimator, rf_model, rf_estimator_tuned]\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "\n",
    "# looping through all the models to get the accuracy,recall and precision scores\n",
    "for model in models:\n",
    "     # accuracy score\n",
    "    j = get_accuracy_score(model,False)\n",
    "    acc_train.append(j[0])\n",
    "    acc_test.append(j[1])\n",
    "\n",
    "    # recall score\n",
    "    k = get_recall_score(model,False)\n",
    "    recall_train.append(k[0])\n",
    "    recall_test.append(k[1])\n",
    "\n",
    "    # precision score\n",
    "    l = get_precision_score(model,False)\n",
    "    precision_train.append(l[0])\n",
    "    precision_test.append(l[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Mention the Model names in the list. for example 'Model': ['Decision Tree', 'Tuned Decision Tree'..... write tht names of all model built]\n",
    "# Remove _________ and complete the code\n",
    "\n",
    "comparison_frame = pd.DataFrame({'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'Random Forest Truned'], \n",
    "                                          'Train_Accuracy': acc_train,\n",
    "                                          'Test_Accuracy': acc_test,\n",
    "                                          'Train_Recall': recall_train,\n",
    "                                          'Test_Recall': recall_test,\n",
    "                                          'Train_Precision': precision_train,\n",
    "                                          'Test_Precision': precision_test}) \n",
    "comparison_frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>Insights: The Tuned Random Forest appears to have the best overall performace based off the metrics above. However, I believe I can achieve better results with some more turning or possible some different methods.</strong></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>1. Refined insights -</strong> What are the most meaningful insights from the data relevant to the problem?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>2. Comparison of various techniques and their relative performance -</strong> How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong>3. Proposal for the final solution design -</strong> What model do you propose to be adopted? Why is this the best solution to adopt?</p>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

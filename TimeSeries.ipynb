{
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h1 id=\"Project:-Time-Series---Forecasting-Stock-Prices\"><strong>Project: Time Series - Forecasting Stock Prices</strong><a class=\"anchor-link\" href=\"#Project:-Time-Series---Forecasting-Stock-Prices\">\u00b6</a></h1><h1 id=\"Marks:-30\">Marks: 30<a class=\"anchor-link\" href=\"#Marks:-30\">\u00b6</a></h1><p>Welcome to the project on Time Series. We will use the Amazon Stock Prices dataset for this project.</p>\n<hr/>\n<h2 id=\"Context:\"><strong>Context:</strong><a class=\"anchor-link\" href=\"#Context:\">\u00b6</a></h2><hr/>\n<p><strong>Stocks are one of the most popular financial instruments invented for building wealth</strong> and are the <strong>centerpiece of any investment portfolio.</strong> Recent advances in trading technology have opened up stock markets in such a way that nowadays, <strong>nearly anybody can own stock.</strong></p>\n<p>In the last few decades, there's been an <strong>explosive increase in the average person's interest for the stock market.</strong> This makes stock value prediction an interesting and popular problem to explore.</p>\n<hr/>\n<h2 id=\"Objective:\"><strong>Objective:</strong><a class=\"anchor-link\" href=\"#Objective:\">\u00b6</a></h2><hr/>\n<p>Amazon.com, Inc. engages in the retail sale of consumer products and subscriptions in North America as well as internationally. This dataset consists of monthly average stock closing prices of Amazon over a period of 12 years from 2006 to 2017. We have to <strong>build a time series model</strong> using the AR, MA, ARMA and ARIMA models in order to <strong>forecast the stock closing price of Amazon.</strong></p>\n<hr/>\n<h2 id=\"Data-Dictionary:\"><strong>Data Dictionary:</strong><a class=\"anchor-link\" href=\"#Data-Dictionary:\">\u00b6</a></h2><hr/>\n<ul>\n<li><strong>date:</strong> Date when the price was collected</li>\n<li><strong>close:</strong> Closing price of the stock</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Importing-libraries\">Importing libraries<a class=\"anchor-link\" href=\"#Importing-libraries\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Install this to upgrade the statsmodels package. It will be required to use AR, MA, & ARMA models\n#!pip install statsmodels --upgrade\n!pip install statsmodels==0.12.1\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#If the above command doesn't work, please run the below command in the anaconda prompt, otherwise ignore\n#conda install statsmodels\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Importing libraries for data manipulation\nimport pandas as pd\nimport numpy as np\n\n#Importing libraries for visualization\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\n#Importing library for date manipulation\nfrom datetime import datetime\n\n#To calculate the MSE or RMSE\nfrom sklearn.metrics import mean_squared_error\n\n#Importing acf and pacf functions\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\n#Importing models from statsmodels library\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom statsmodels.tsa.arima.model import ARIMA\n\n#To ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Reading-the-dataset\">Reading the dataset<a class=\"anchor-link\" href=\"#Reading-the-dataset\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#If you are having an issue while loading the excel file in pandas, please run the below command in anaconda prompt, otherwise ignore.\n#conda install -c anaconda xlrd\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\ndf = pd.read_excel('amazon_stocks_prices.xlsx')\ndf.head()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Checking-info\">Checking info<a class=\"anchor-link\" href=\"#Checking-info\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-1:-Check-the-info-of-the-dataset-and-write-your-observations.-(2-Marks)\"><strong>Question 1: Check the info of the dataset and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-1:-Check-the-info-of-the-dataset-and-write-your-observations.-(2-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Write your code here\ndf.info()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:There are two columns with 144 rows of data. There doesn't appear to be any missing values.  </strong></p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Setting date as the index\ndf = df.set_index(['date'])\ndf.head()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>Now, let's <strong>visualize the time series</strong> to get an idea about the trend and/or seasonality within the data.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Visualizing the time series\nplt.figure(figsize=(16,8))\nplt.xlabel(\"Month\")\nplt.ylabel(\"Closing Prices\")\nplt.title('Amazon Stock Prices')\nplt.plot(df.index, df.close, color = 'c', marker='.')\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>We can see that the series has an <strong>upward trend with some seasonality.</strong> This implies that the <strong>average stock price of Amazon has been increasing almost every year.</strong></li>\n<li>Before building different models, it is important to <strong>check whether the series is stationary or not.</strong></li>\n</ul>\n<p>Let us first split the dataset into train and test data</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Splitting-the-dataset\">Splitting the dataset<a class=\"anchor-link\" href=\"#Splitting-the-dataset\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Splitting the data into train and test\ndf_train = df.loc['2006-01-01':'2015-12-01']\ndf_test = df.loc['2016-01-01' : '2017-12-01']\nprint(df_train)\nprint(df_test)\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>Now let us check the <strong>rolling mean and standard deviation</strong> of the series to <strong>visualize if the series has any trend or seasonality.</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Testing-the-stationarity-of-the-series\">Testing the stationarity of the series<a class=\"anchor-link\" href=\"#Testing-the-stationarity-of-the-series\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Calculating the rolling mean and standard deviation for a window of 12 observations\nrolmean=df_train.rolling(window=12).mean()\nrolstd=df_train.rolling(window=12).std()\n\n#Visualizing the rolling mean and standard deviation\n\nplt.figure(figsize=(16,8))\nactual = plt.plot(df_train, color='c', label='Actual Series')\nrollingmean = plt.plot(rolmean, color='red', label='Rolling Mean') \n#rollingstd = plt.plot(rolstd, color='green', label='Rolling Std. Dev.')\nplt.title('Rolling Mean & Standard Deviation of the Series')\nplt.legend()\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>We can see there is an upward trend in the series.</li>\n<li>We can confirm that <strong>the series is not stationary.</strong></li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>We can also use the <strong>Augmented Dickey-Fuller (ADF) Test</strong> to verify if the series is stationary or not.\nThe null and alternate hypotheses for the ADF Test are defined as:</p>\n<ul>\n<li><strong>Null hypothesis:</strong> The Time Series is non-stationary</li>\n<li><strong>Alternative hypothesis:</strong> The Time Series is stationary</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Define a function to use adfuller test\ndef adfuller(df_train):\n  #Importing adfuller using statsmodels\n  from statsmodels.tsa.stattools import adfuller\n  print('Dickey-Fuller Test: ')\n  adftest = adfuller(df_train['close'])\n  adfoutput = pd.Series(adftest[0:4], index=['Test Statistic','p-value','Lags Used','No. of Observations'])\n  for key,value in adftest[4].items():\n    adfoutput['Critical Value (%s)'%key] = value\n  print(adfoutput)\nadfuller(df_train)\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ol>\n<li>From the above test, we can see that the <strong>p-value = 1 i.e. &gt; 0.05</strong> (For 95% confidence intervals) therefore, <strong>we fail to reject the null hypothesis.</strong></li>\n<li>Hence, <strong>we can confirm that the series is non-stationary.</strong></li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Making-the-series-stationary\">Making the series stationary<a class=\"anchor-link\" href=\"#Making-the-series-stationary\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>We can use some of the following methods to convert a non-stationary series into a stationary one:</p>\n<ol>\n<li><strong>Log Transformation</strong></li>\n<li><strong>By differencing the series (lagged series)</strong></li>\n</ol>\n<p>Let's first use a log transformation over this series to remove exponential variance and check the stationarity of the series again.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Visualize the rolling mean and standard deviation after using log transformation\nplt.figure(figsize=(16,8))\ndf_log = np.log(df_train)\nMAvg = df_log.rolling(window=12).mean()\nMStd = df_log.rolling(window=12).std()\nplt.plot(df_log)\nplt.plot(MAvg, color='r', label = 'Moving Average')\nplt.plot(MStd, color='g', label = 'Standard Deviation')\nplt.legend()\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>Since <strong>we can still see the upward trend in the series</strong>, we can conclude that <strong>the series is still non-stationary.</strong> </li>\n<li>However, the standard deviation is almost constant which implies that <strong>now the series has constant variance.</strong></li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n \n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Let's shift the series by order 1 (or by 1 month) &amp; apply differencing (using lagged series)</strong> and then check the rolling mean and standard deviation.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-2:-Visualize-the-rolling-mean-and-rolling-standard-deviation-of-the-shifted-series-(df_shift)-and-check-the-stationarity-by-calling-the-adfuller()-function.-Also,-write-your-observations-on-the-same.-(3-Marks)\"><strong>Question 2: Visualize the rolling mean and rolling standard deviation of the shifted series (df_shift) and check the stationarity by calling the adfuller() function. Also, write your observations on the same. (3 Marks)</strong><a class=\"anchor-link\" href=\"#Question-2:-Visualize-the-rolling-mean-and-rolling-standard-deviation-of-the-shifted-series-(df_shift)-and-check-the-stationarity-by-calling-the-adfuller()-function.-Also,-write-your-observations-on-the-same.-(3-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nplt.figure(figsize=(16,8))\ndf_shift = df_log - df_log.shift(periods = 1)\nMAvg_shift = df_shift.rolling(window=12).mean()\nMStd_shift = df_shift.rolling(window=12).std()\nplt.plot(df_shift, color='c')\nplt.plot(MAvg_shift, color='red', label = 'Moving Average')\nplt.plot(MStd_shift, color='green', label = 'Standard Deviation')\nplt.legend()\nplt.show()\n\n#Dropping the null values that we get after applying differencing method\ndf_shift = df_shift.dropna()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:The mean and standard deviation look somewhat constant so we can now test stantionarity</strong></p>\n<p>Let us use the adfuller test to check the stationarity.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n \n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nadfuller(df_shift) # call the adfuller function for df_shift series\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li><strong>The P Value is extrememly small, significantly less than 0.05. We can reject the Null hypothesis of the series being non-stationary. </strong></li>\n</ul>\n<p>Let's decompose the time series to check its different components.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Decomposing-the-time-series-components-into-Trend,-Seasonality-and-Residual\">Decomposing the time series components into Trend, Seasonality and Residual<a class=\"anchor-link\" href=\"#Decomposing-the-time-series-components-into-Trend,-Seasonality-and-Residual\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Importing the seasonal_decompose function to decompose the time series\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomp = seasonal_decompose(df_train)\n\ntrend = decomp.trend\nseasonal = decomp.seasonal\nresidual = decomp.resid\n\nplt.figure(figsize=(15,10))\nplt.subplot(411)\nplt.plot(df_train, label='Actual', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(trend, label='Trend', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(seasonal, label='Seasonality', marker='.')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(residual, label='Residuals', marker='.')\nplt.legend(loc='upper left')\nplt.tight_layout()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>We can see that there are significant <strong>trend, seasonality and residuals components</strong> in the series</li>\n<li>The plot for seasonality shows that <strong>Amazon's stock prices spike in July, September, and December.</strong></li>\n</ul>\n<p><strong>Now let's move on to the model building section. First, we will plot the <code>ACF</code> and <code>PACF</code> plots to get the values of p and q i.e. order of AR and MA models to be used.</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Plotting-the-auto-correlation-function-and-partial-auto-correlation-function-to-get-p-and-q-values-for-AR,-MA,-ARMA,-and-ARIMA-models\">Plotting the auto-correlation function and partial auto-correlation function to get p and q values for AR, MA, ARMA, and ARIMA models<a class=\"anchor-link\" href=\"#Plotting-the-auto-correlation-function-and-partial-auto-correlation-function-to-get-p-and-q-values-for-AR,-MA,-ARMA,-and-ARIMA-models\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n\nplt.figure(figsize = (16,8))\nplot_acf(df_shift, lags = 12) \nplt.show() \nplot_pacf(df_shift, lags = 12) \nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>From the above PACF plot we can see that <strong>the highest lag</strong> at which the plot extends beyond the statistically significant boundary is <strong>lag 1.</strong> </li>\n<li>This indicates that an <strong>AR Model of lag 1 (p=1)</strong> should be sufficient to fit the data.</li>\n<li>Similarly, from the ACF plot, we can infer that <strong>q=1.</strong></li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"AR-Model\">AR Model<a class=\"anchor-link\" href=\"#AR-Model\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-3:-Fit-and-predict-the-shifted-series-with-the-AR-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(5-Marks)\"><strong>Question 3: Fit and predict the shifted series with the AR Model and calculate the RMSE. Also, visualize the time series and write your observations. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-3:-Fit-and-predict-the-shifted-series-with-the-AR-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(5-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Importing AutoReg function to apply AR model\nfrom statsmodels.tsa.ar_model import AutoReg\n\nplt.figure(figsize=(16,8))\nmodel_AR = AutoReg(df_shift, lags=1) #Use number of lags as 1 and apply AutoReg function on df_shift series\nresults_AR = model_AR.fit() #fit the model\nplt.plot(df_shift)\npredict = results_AR.predict(start=0,end=len(df_shift)-1) #predict the series \npredict = predict.fillna(0) #Converting NaN values to 0\nplt.plot(predict, color='red')\nplt.title('AR Model - RMSE: %.4f'% mean_squared_error(predict,df_shift['close'], squared=False))  #Calculating rmse\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:We can see the root mean squared error is 0.09</strong></p>\n<p><strong>Let's check the AIC value</strong> of the model</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nresults_AR.aic\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>Now, let's build MA, ARMA, and ARIMA models as well, and see if we can get a better model</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"MA-Model\">MA Model<a class=\"anchor-link\" href=\"#MA-Model\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>We will be using an ARIMA model with p=0 and d=0 so that it will work as an MA model</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-4:-Fit-and-predict-the-shifted-series-with-the-MA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 4: Fit and predict the shifted series with the MA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-4:-Fit-and-predict-the-shifted-series-with-the-MA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nfrom statsmodels.tsa.arima_model import ARIMA\nplt.figure(figsize=(16,8))\nmodel_MA = ARIMA(df_shift, order=(0, 0, 1)) #Using p=0, d=0, q=1 and apply ARIMA function on df_shift series\nresults_MA = model_MA.fit()#fit the model\nplt.plot(df_shift)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('MA Model - RMSE: %.4f'% mean_squared_error(results_MA.fittedvalues,df_shift['close'], squared=False))\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:The RMSE is 0.0902 which is essencially the same as the AR model.</strong></p>\n<p>Let's check the AIC value of the model</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nresults_MA.aic\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<ul>\n<li><strong>The MA model is giving a much lower AIC</strong> when compared to the AR model, implying that <strong>the MA model fits the training data better.</strong> </li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"ARMA-Model\">ARMA Model<a class=\"anchor-link\" href=\"#ARMA-Model\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>We will be using an <strong>ARIMA model with p=1 and q=1</strong> (as observed from the ACF and PACF plots) <strong>and d=0 so that it will work as an ARMA model.</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-5:-Fit-and-predict-the-shifted-series-with-the-ARMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 5: Fit and predict the shifted series with the ARMA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-5:-Fit-and-predict-the-shifted-series-with-the-ARMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nplt.figure(figsize=(16,8))\nmodel_ARMA = ARIMA(df_shift, order=(1, 0, 1)) #Using p=1, d=0, q=1 and apply ARIMA function on df_shift series\nresults_ARMA = model_ARMA.fit() #fit the model\nplt.plot(df_shift)\nplt.plot(results_ARMA.fittedvalues, color='red')\nplt.title('ARMA Model - RMSE: %.4f'% mean_squared_error(results_ARMA.fittedvalues,df_shift['close'], squared=False))\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li><strong>The ARMA is giving the same RMSE as the MR model. </strong></li>\n</ul>\n<p><strong>Let's check the AIC value</strong> of the model</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nresults_ARMA.aic\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<ul>\n<li><strong>The AIC value of the ARMA model is more or less similar</strong> to MA model </li>\n</ul>\n<p><strong>Let us try using the ARIMA Model.</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"ARIMA-Model\">ARIMA Model<a class=\"anchor-link\" href=\"#ARIMA-Model\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>We will be using an <strong>ARIMA Model with p=1, d=1, &amp; q=1</strong>.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-6:-Fit-and-predict-the-shifted-series-with-the-ARIMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\"><strong>Question 6: Fit and predict the shifted series with the ARIMA Model and calculate the RMSE. Also, visualize the time series and write your observations. (2 Marks)</strong><a class=\"anchor-link\" href=\"#Question-6:-Fit-and-predict-the-shifted-series-with-the-ARIMA-Model-and-calculate-the-RMSE.-Also,-visualize-the-time-series-and-write-your-observations.-(2-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n \n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n \n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nfrom statsmodels.tsa.arima_model import ARIMA\n\nplt.figure(figsize=(16,8))\nmodel_ARIMA = ARIMA(df_log, order=(1,1,1)) #Using p=1, d=1, q=1 and apply ARIMA function on df_log series\nresults_ARIMA = model_ARIMA.fit() #fit the model\nplt.plot(df_shift)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('ARIMA Model - RMSE: %.4f'% mean_squared_error(results_ARIMA.fittedvalues,df_shift['close'], squared=False))\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:We get an RMSE of 0.0902, which is exactly the same as all the other models other than AR</strong></p>\n<p><strong>Let's check the AIC value</strong> of the model</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nresults_ARIMA.aic\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<ul>\n<li><strong>The AIC value of the ARIMA model is the same</strong> as the ARMA model. </li>\n</ul>\n<p>We can see that <strong>all the models return almost the same RMSE.</strong> There is not much difference in AIC value as well across all the models except for the AR model.</p>\n<p><strong>We can choose to predict the values using ARIMA as it takes into account more factors than AR, MA, ARMA models.</strong></p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Printing the fitted values\npredictions=pd.Series(results_ARIMA.fittedvalues)\npredictions\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Inverse-Transformation\">Inverse Transformation<a class=\"anchor-link\" href=\"#Inverse-Transformation\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>Now we have fitted values using the ARIMA model, <strong>we will use the inverse transformation to get back the original values.</strong></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-7:-Apply-an-inverse-transformation-on-the-predictions-of-the-ARIMA-Model.-(5-Marks)\"><strong>Question 7: Apply an inverse transformation on the predictions of the ARIMA Model. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-7:-Apply-an-inverse-transformation-on-the-predictions-of-the-ARIMA-Model.-(5-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#First step - doing cumulative sum\npredictions_cumsum = predictions.cumsum() # use .cumsum fuction on the predictions\npredictions_cumsum\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Second step - Adding the first value of the log series to the cumulative sum values\npredictions_log = pd.Series(df_log['close'].iloc[0], index=df_log.index)\npredictions_log = predictions_log.add(predictions_cumsum, fill_value=0)\npredictions_log\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Third step - applying exponential transformation\npredictions_ARIMA = np.exp(predictions_log) #use exponential function\npredictions_ARIMA\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Plotting the original vs predicted series\nplt.figure(figsize=(16,8))\nplt.plot(df_train, color = 'c', label = 'Original Series')  #plot the original train series\nplt.plot(predictions_ARIMA, color = 'r', label = 'Predicted Series')  #plot the predictions_ARIMA \nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li>We can see that <strong>the predicted series is very similar to the original series</strong> i.e. The model is good at predicting values on the training data except for the dip in stock prices in 2015 which may have been due to some external factors that are not included in this model. </li>\n<li>Let us <strong>forecast the closing prices for the next 24 months.</strong></li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Forecasting-the-values-for-next-24-months-and-compare-it-with-test-data\">Forecasting the values for next 24 months and compare it with test data<a class=\"anchor-link\" href=\"#Forecasting-the-values-for-next-24-months-and-compare-it-with-test-data\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>To forecast the values for the next 24 months using the ARIMA model, we need to follow the steps below:</strong></p>\n<ol>\n<li>Forecast the log-transformed fitted values for the next 24 months</li>\n<li>Make a list of these 24 month (2016-2017) forecasted values</li>\n<li>Convert that list into a series so that we can work with pandas functions </li>\n<li>Make a dataframe where we have the dates starting from 2016-01-01 to 2017-12-01 as the index and the respective forecasted values</li>\n<li>Apply the inverse transformation and get the real forecasted values</li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-8:-Forecast-the-stocks-prices-for-the-next-24-months-and-perform-the-inverse-transformation.-(5-Marks)\"><strong>Question 8: Forecast the stocks prices for the next 24 months and perform the inverse transformation. (5 Marks)</strong><a class=\"anchor-link\" href=\"#Question-8:-Forecast-the-stocks-prices-for-the-next-24-months-and-perform-the-inverse-transformation.-(5-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Forecasting the values for next 24 months\nforecasted_ARIMA = results_ARIMA.forecast(steps=24) #forecast using the results_ARIMA for next 24 months. Keep steps=24\nforecasted_ARIMA[0]\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n# Creating a list containing all the forecasted values\nlist1 = forecasted_ARIMA[0].tolist()\nseries1 = pd.Series(list1)\nseries1\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Making a new dataframe to get the additional dates from 2016-2018\nindex = pd.date_range('2016-01-1','2018-1-1' , freq='1M')- pd.offsets.MonthBegin(1)\ndf1 = pd.DataFrame()\ndf1['forecasted'] = series1\ndf1.index = index\ndf1\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Applying exponential transformation to the forecasted log values\nforecasted_ARIMA = np.exp(df1['forecasted']) #use exponential function on forecasted data\nforecasted_ARIMA\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p>Now, let's try to visualize the original data with the predicted values on the training data and the forecasted values.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\n#Plotting the original vs predicted series\nplt.figure(figsize=(16,8))\nplt.plot(df, color = 'c', label = 'Original Series')\nplt.plot(predictions_ARIMA, color = 'r', label = 'Prediction on Train data') #plot the predictions_ARIMA series\nplt.plot(forecasted_ARIMA, label = 'Prediction on Test data', color='b')  #plot the forecasted_ARIMA series\nplt.title('Actual vs Predicted')\nplt.legend()\nplt.show()\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>Observations:</strong></p>\n<ul>\n<li><strong>As observed earlier, most of the predicted values on the training data are very close to the actual values</strong> except for the dip in stock prices in the year 2015.</li>\n<li><strong>On the test data, the model is able to correctly predict the trend of the stock prices</strong>, as we can see that the blue line appears to be close to the actual values (cyan blue) and they both have an upward trend. <strong>However the test predictions are not able to identify the volatile variations in the stock prices over the last 2 years.</strong></li>\n</ul>\n<p>Let's test the RMSE of the transformed predictions and the original value on the training and testing data to check whether the model is giving a generalized performance or not.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Question-9:-Check-the-RMSE-on-the-original-train-and-test-data-and-write-your-conclusion-from-the-above-analysis.-(4-Marks)\"><strong>Question 9: Check the RMSE on the original train and test data and write your conclusion from the above analysis. (4 Marks)</strong><a class=\"anchor-link\" href=\"#Question-9:-Check-the-RMSE-on-the-original-train-and-test-data-and-write-your-conclusion-from-the-above-analysis.-(4-Marks)\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nfrom sklearn.metrics import mean_squared_error\nerror = mean_squared_error(predictions_ARIMA, df_train, squared = False) #calculate RMSE using the predictions_ARIMA and df_train \nerror\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n\nfrom sklearn.metrics import mean_squared_error\nerror = mean_squared_error(forecasted_ARIMA, df_test, squared = False)  #calculate RMSE using the forecasted_ARIMA and df_test\nerror\n\n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<h3 id=\"Conclusion\">Conclusion<a class=\"anchor-link\" href=\"#Conclusion\">\u00b6</a></h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n<p><strong>The RMSE is lower on the Training data as apposed to the test data. We can see in the graph above that this is most likely do to the volitility in the test data with more peaks and values. However, the overal direction of the stock is accurately predicted, just not all the highs and lows. \nOur model will accurately predict the overall direction of the stock. For log term this is quite beneficial. However, if it is desired to have a more accurate represntation of the peaks and valleys, then a more complex model may be needed. This shortcoming was also viewed in the training data when we missed predicting the dip in 2015.</strong></p>\n"
      ]
    }
  ],
  "metadata": {}
}